{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CogPonder: N-Back PyTorch Lightning\n",
    "\n",
    "This notebook implements the CogPonder algorithm using PyTorch Lightning. It assumes fixed hyperparameters and fits the model to a single-subject dataset. It wraps a simple RRN with a pondering lambda layer and trains it on the *Self-Regulation Ontology* dataset.\n",
    "\n",
    "## Data\n",
    "\n",
    "Either N-back or Stroop is used as the dataset. The data is loaded from the `data/Self_Regulation_ontology/` directory.\n",
    "\n",
    "### Input and Output\n",
    "\n",
    "#### N-Back\n",
    "\n",
    "Previous N+1 presented symbols are used as input, the last input is the current symbol. The output is the human response to the N+1th trial.\n",
    "\n",
    "#### Stroop\n",
    "\n",
    "The input is the color and letter of the current stimuli. The output is the human response to the current trial.\n",
    "\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "- `n_embeddings`: number of hidden units in the recurrent ICOM model. Defaults to $N_{\\text{symbols} + 1}$\n",
    "- `rec_loss_beta`: the beta parameter of the loss function. Defaults to 0.5.\n",
    "- `cog_loss_beta`: the beta parameter of the loss function. Defaults to 0.5.\n",
    "- `learning_rate`: the learning rate of the optimizer. Defaults to 0.0001.\n",
    "- `max_response_step`: maximum response step in the dataset. Defaults to $\\max(\\text{response\\_step}) + 10$.\n",
    "\n",
    "## Criterion\n",
    "\n",
    "$L = L_{\\text{reconstruction}} + L_{\\text{cognitive}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from ray import tune, air\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "from functools import partial\n",
    "from pytorch_lightning.callbacks import RichProgressBar, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from cogponder import CogPonderModel\n",
    "from cogponder.datasets import StroopSRODataset, NBackSRODataset, CogPonderDataModule\n",
    "from pathlib import Path\n",
    "\n",
    "from cogponder.losses import ReconstructionLoss, CognitiveLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Stroop dataset...\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and configs\n",
    "\n",
    "TASK = 'stroop'  # or stroop\n",
    "\n",
    "match TASK:\n",
    "    case 'nback':\n",
    "        print('Loading N-back dataset...')\n",
    "        data = NBackSRODataset(n_subjects=1, n_back=2) # shape (n_subjects, (...))\n",
    "        n_symbols = torch.unique(data[0][0]).shape[0]\n",
    "        embeddings_dim = n_symbols\n",
    "        max_response_step = 30 # OR something like \"2 * max observed RT\"\n",
    "    case 'stroop':\n",
    "        print('Loading Stroop dataset...')\n",
    "        data = StroopSRODataset(n_subjects=1)\n",
    "        embeddings_dim = 2\n",
    "        max_response_step = 100\n",
    "\n",
    "# parameter space\n",
    "CONFIG = {\n",
    "    'rec_loss_beta': 1.,\n",
    "    'cog_loss_beta': .5,\n",
    "    'loss_by_trial_type': False,\n",
    "    'learning_rate': 1e-2,\n",
    "    'max_response_step': max_response_step,\n",
    "    'inputs_dim': data[0][0].size(1),\n",
    "    'embeddings_dim': embeddings_dim,\n",
    "    'auto_lr_find': False,\n",
    "    'task': TASK,\n",
    "    'batch_size': 196\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name           </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         In sizes </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Out sizes </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ train_accuracy │ Accuracy           │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">         ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ val_accuracy   │ Accuracy           │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">         ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ cog_loss_fn    │ CognitiveLoss      │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">         ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ rec_loss_fn    │ ReconstructionLoss │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">         ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ halt_node      │ Sequential         │      9 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">           [1, 2] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    [1, 1] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ output_node    │ Sequential         │      9 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">           [1, 2] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    [1, 1] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ recurrent_node │ GRUCell            │     36 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [[1, 2], [1, 2]] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    [1, 2] </span>│\n",
       "└───┴────────────────┴────────────────────┴────────┴──────────────────┴───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName          \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m        In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mOut sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ train_accuracy │ Accuracy           │      0 │\u001b[37m \u001b[0m\u001b[37m               ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m        ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ val_accuracy   │ Accuracy           │      0 │\u001b[37m \u001b[0m\u001b[37m               ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m        ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ cog_loss_fn    │ CognitiveLoss      │      0 │\u001b[37m \u001b[0m\u001b[37m               ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m        ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ rec_loss_fn    │ ReconstructionLoss │      0 │\u001b[37m \u001b[0m\u001b[37m               ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m        ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ halt_node      │ Sequential         │      9 │\u001b[37m \u001b[0m\u001b[37m          [1, 2]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m   [1, 1]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ output_node    │ Sequential         │      9 │\u001b[37m \u001b[0m\u001b[37m          [1, 2]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m   [1, 1]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ recurrent_node │ GRUCell            │     36 │\u001b[37m \u001b[0m\u001b[37m[[1, 2], [1, 2]]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m   [1, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "└───┴────────────────┴────────────────────┴────────┴──────────────────┴───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 54                                                                                               \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 54                                                                                                   \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 54                                                                                               \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 54                                                                                                   \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eadabaacdff4a3193765817ac14a3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/Caskroom/miniforge/base/envs/ponder/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/da\n",
       "ta_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be\n",
       "a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/Caskroom/miniforge/base/envs/ponder/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/da\n",
       "ta_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be\n",
       "a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/Caskroom/miniforge/base/envs/ponder/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/da\n",
       "ta_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be\n",
       "a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/Caskroom/miniforge/base/envs/ponder/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/da\n",
       "ta_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be\n",
       "a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pondering model\n",
    "\n",
    "datamodule = CogPonderDataModule(data, batch_size=CONFIG['batch_size'], num_workers=1)\n",
    "model = CogPonderModel(CONFIG, example_input_array=data[0][0][:1].to(device))\n",
    "\n",
    "# # DEBUG\n",
    "# X = data[0][0][:10]\n",
    "# y_true = data[0][3][:10]\n",
    "# rt_true = data[0][4][:10]\n",
    "# y_steps, p_halts, rt_pred = model(X)\n",
    "# loss_func = CognitiveLoss(CONFIG['max_response_step'])\n",
    "# l = loss_func(rt_pred, rt_true)\n",
    "# 'l', l, rt_pred, rt_true\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1000,\n",
    "    # min_epochs=1000,\n",
    "    accelerator='auto',\n",
    "    auto_lr_find=CONFIG['auto_lr_find'],\n",
    "    log_every_n_steps=1,\n",
    "    overfit_batches=True,\n",
    "    # accumulate_grad_batches=2,\n",
    "    callbacks=[\n",
    "        RichProgressBar(),\n",
    "        EarlyStopping(monitor='val_loss', patience=100, mode='min', min_delta=0.001),\n",
    "    ])\n",
    "\n",
    "if CONFIG['auto_lr_find']:\n",
    "    trainer.tune(model, datamodule=datamodule)\n",
    "\n",
    "trainer.fit(model, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: Plot LR tuning results\n",
    "# lr_finder = trainer.tuner.lr_find(model, max_lr=2, datamodule=datamodule)\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()\n",
    "# model.hparams.learning_rate = lr_finder.suggestion()\n",
    "# trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "X_train, _, _, y_train, rt_train = datamodule.dataset[datamodule.train_dataset.indices]\n",
    "X_test, _, _, y_test, rt_test = datamodule.dataset[datamodule.test_dataset.indices]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_steps,_,rt_train_pred = model(X_train.to(device))\n",
    "    y_test_steps,_,rt_test_pred = model(X_test.to(device))\n",
    "\n",
    "    y_train_pred = y_train_steps.gather(dim=0, index=rt_train_pred[None, :] - 1,)[0]  # (batch_size,)\n",
    "    y_test_pred = y_test_steps.gather(dim=0, index=rt_test_pred[None, :] - 1,)[0]  # (batch_size,)\n",
    "\n",
    "    accuracy_fn = torchmetrics.Accuracy().to(device)\n",
    "    train_accuracy = accuracy_fn(y_train_pred, y_train.int().to(device))\n",
    "    print('TRAIN ACCURACY', train_accuracy.item())\n",
    "\n",
    "    accuracy_fn = torchmetrics.Accuracy().to(device)\n",
    "    test_accuracy = accuracy_fn(y_test_pred, y_test.int().to(device))\n",
    "    print('TEST ACCURACY', test_accuracy.item())\n",
    "\n",
    "    # DEBUG report the ground truth and predicted response times\n",
    "    print('TRUE TRAIN:', rt_train.detach().tolist(), '\\nPRED TRAIN:',  rt_train_pred.tolist())\n",
    "    print('TRUE TEST:', rt_test.detach().tolist(), '\\nPRED TEST:',  rt_test_pred.tolist())\n",
    "\n",
    "# DEBUG report medians\n",
    "# rt_train_pred.median(), rt_train.float().median()\n",
    "# rt_test_pred.median(), rt_test.float().median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RT_CAP = max_response_step # data[0][4].max().item()\n",
    "\n",
    "sns.ecdfplot(rt_train, label='True (train)')\n",
    "sns.ecdfplot(rt_train_pred[rt_train_pred < RT_CAP].cpu(), label='Predicted (train)')\n",
    "\n",
    "plt.title('Evaluation of PonderNet on simulated train split')\n",
    "plt.xlabel('response time (steps)')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "sns.ecdfplot(rt_test, label='True (test)')\n",
    "sns.ecdfplot(rt_test_pred[rt_test_pred < RT_CAP].cpu(), label='Predicted (test)')\n",
    "\n",
    "plt.title('Evaluation of PonderNet on simulated test split')\n",
    "plt.xlabel('response time (steps)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.kdeplot(rt_train, label='Train (TRUE)', cut=0)\n",
    "sns.kdeplot(rt_train_pred[rt_train_pred < RT_CAP].cpu(), label='Train (PRED)', cut=0)\n",
    "\n",
    "sns.kdeplot(rt_test, label='Test (TRUE)', cut=0)\n",
    "sns.kdeplot(rt_test_pred[rt_test_pred < RT_CAP].cpu(), label='Test (PRED)', cut=0)\n",
    "\n",
    "\n",
    "plt.title('Evaluation of PonderNet on SRO single-subject 2-back')\n",
    "plt.xlabel('response time (steps)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ponder')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76027f054aa38c6d5055560f9009a0f692d2c97ebd1740bbb514e2260aad097b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
