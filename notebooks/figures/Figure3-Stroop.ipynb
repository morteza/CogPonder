{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rc('text', usetex=False)\n",
    "mpl.rc('font', family='serif', size=12)\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from src.cogponder import CogPonderModel\n",
    "from src.cogponder.data import StroopSRODataset, CogPonderDataModule, NBackSRODataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook only fits one SRO subject, which its SRO-SubjectID can be defined here\n",
    "\n",
    "# upon successful training, the model will be saved to this path\n",
    "# CHECKPOINT_PATH = Path('models/stroop/') / f'cogponder_subject-{SRO_SUBJECT_ID}_epochs-10000.ckpt'\n",
    "CHECKPOINT_PATH = Path('models/checkpoints/stroop/cogponder_epochs-413.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "\n",
    "# DEBUG - Load the checkpoint\n",
    "\n",
    "model_ckpt = CogPonderModel.load_from_checkpoint(CHECKPOINT_PATH)\n",
    "model_ckpt.eval()\n",
    "\n",
    "print('loading data module...', end='')\n",
    "dataset = StroopSRODataset(n_subjects=1, step_duration=20)\n",
    "datamodule = CogPonderDataModule(dataset, num_workers=8)\n",
    "datamodule.prepare_data()\n",
    "print('Done!')\n",
    "\n",
    "subject_ids, trial_ids, contexts, stimuli, y_human, rt_human, y_correct = datamodule.test_dataset[:]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_ckpt.eval()\n",
    "\n",
    "    print('Predicting responses...', end='')\n",
    "    y_pred, y_steps, p_halts, rt_pred = model_ckpt(stimuli, subject_ids, contexts)\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_stats = pd.DataFrame({\n",
    "    'condition': contexts,\n",
    "    'subject': subject_ids,\n",
    "    'response_time': rt_human * dataset.step_duration,\n",
    "    'accuracy': (stimuli[:,0, 0] == y_correct).float() * 100,\n",
    "    'agent': 'Human data',\n",
    "})\n",
    "\n",
    "cogponder_stats = pd.DataFrame({\n",
    "    'condition': contexts,\n",
    "    'subject': subject_ids,\n",
    "    'response_time': (rt_pred * dataset.step_duration).float(),\n",
    "    'accuracy': (stimuli[:,0, 0] == y_pred).float() * 100,\n",
    "    'agent': 'CogPonder agent',\n",
    "})\n",
    "\n",
    "# cogponder_stats['condition'] = cogponder_stats['condition'].map({0: 'Incongruent', 1: 'Congruent'})\n",
    "# human_stats['condition'] = human_stats['condition'].map({0: 'Incongruent', 1: 'Congruent'})\n",
    "\n",
    "stats = pd.concat([human_stats, cogponder_stats]).reset_index()\n",
    "\n",
    "mean_accuracy = stats.groupby(['agent', 'condition'])['accuracy'].mean()\n",
    "median_rt = stats.groupby(['agent', 'condition'])['response_time'].median()\n",
    "\n",
    "median_rt, mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = stats.melt(\n",
    "    id_vars=['condition', 'agent'],\n",
    "    value_vars=['response_time', 'accuracy'],\n",
    "    var_name='measure'\n",
    ")\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=plot_data, x='condition', y='value', col='measure', hue='agent',\n",
    "    kind=\"bar\", height=3, aspect=1.2,\n",
    "    width=.3, errorbar=('ci', 95), capsize=.065, errwidth=1,\n",
    "    palette='Set2',\n",
    "    sharex=False, sharey=False,\n",
    "    estimator='mean',\n",
    "    col_order=['accuracy', 'response_time'],\n",
    "    hue_order=['Human data', 'CogPonder agent'],\n",
    "    order=['Congruent', 'Incongruent'],\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "g.add_legend(loc='upper left', bbox_to_anchor=(.95, .8))\n",
    "\n",
    "g.axes[0,0].set_ylabel('% correct')\n",
    "g.axes[0,0].set_title('Accuracy')\n",
    "g.axes[0,1].set_ylabel('seconds')\n",
    "g.axes[0,1].set_title('Response Time (s)')\n",
    "g.axes[0,0].set_xlabel(None)\n",
    "g.axes[0,1].set_xlabel(None)\n",
    "\n",
    "\n",
    "plt.suptitle('Comparing human and CogPonder performance in the Stroop task', y=1)\n",
    "plt.savefig('outputs/figures/figure3-stroop.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "average_human_performance = pd.DataFrame({\n",
    "    'condition': -1,\n",
    "    'response_time': rt_human * dataset.step_duration,\n",
    "    'accuracy': (y_correct == y_human).float() * 100,\n",
    "    'agent': 'Human data',\n",
    "})\n",
    "\n",
    "human_performance = pd.DataFrame({\n",
    "    'condition': contexts,\n",
    "    'response_time': rt_human * dataset.step_duration,\n",
    "    'accuracy': (y_human == y_correct).float() * 100,\n",
    "    'agent': 'Human data',\n",
    "})\n",
    "\n",
    "cogponder_performance = pd.DataFrame({\n",
    "    'condition': contexts,\n",
    "    'response_time': rt_pred * dataset.step_duration,\n",
    "    'accuracy': (y_correct == y_pred).float() * 100,\n",
    "    'agent': 'CogPonder agent'\n",
    "})\n",
    "\n",
    "average_cogponder_performance = pd.DataFrame({\n",
    "    'condition': -1,\n",
    "    'response_time': rt_pred * dataset.step_duration,\n",
    "    'accuracy': (y_correct == y_pred).float() * 100,\n",
    "    'agent': 'CogPonder agent',\n",
    "})\n",
    "\n",
    "plot_data = pd.concat([human_performance, average_human_performance,\n",
    "                       cogponder_performance, average_cogponder_performance]).reset_index()\n",
    "\n",
    "plot_data['condition'] = plot_data['condition'].map({-1: 'All', 0: 'Incongruent', 1: 'Congruent'})\n",
    "\n",
    "plot_data = plot_data.melt(id_vars=['condition', 'agent'],\n",
    "               value_vars=['response_time', 'accuracy'],\n",
    "               var_name='measure'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=plot_data, x='condition', y='value', col='measure', hue='agent',\n",
    "    kind=\"bar\", height=3, aspect=1.2,\n",
    "    width=.3, errorbar=('ci', 95), capsize=.065, errwidth=1,\n",
    "    palette='Set2',\n",
    "    sharex=False, sharey=False,\n",
    "    estimator='mean',\n",
    "    col_order=['accuracy', 'response_time'],\n",
    "    hue_order=['Human data', 'CogPonder agent'],\n",
    "    order=['All', 'Congruent', 'Incongruent'],\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "g.add_legend(loc='upper left', bbox_to_anchor=(.95, .8))\n",
    "\n",
    "g.axes[0,0].set_ylabel('% correct')\n",
    "g.axes[0,0].set_title('Accuracy')\n",
    "g.axes[0,1].set_ylabel('seconds')\n",
    "g.axes[0,1].set_title('Response Time (s)')\n",
    "g.axes[0,0].set_xlabel(None)\n",
    "g.axes[0,1].set_xlabel(None)\n",
    "\n",
    "\n",
    "plt.suptitle('Comparing human and CogPonder performance in the Stroop task', y=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/figure3-stroop.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4\n",
    "\n",
    "plot_data = pd.DataFrame({\n",
    "    'rt_human': rt_human * dataset.step_duration,\n",
    "    'rt_pred': rt_pred * dataset.step_duration,\n",
    "}).melt()\n",
    "\n",
    "g = sns.displot(\n",
    "    data=plot_data, x='value', hue='variable',\n",
    "    kind='hist', kde=True, fill=True, common_norm=False,\n",
    "    lw=0, alpha=.5, height=3, aspect=1.2,\n",
    "    kde_kws={'cut': 0, 'clip': (0, 2000)},\n",
    "    line_kws={'linewidth': 2},\n",
    "    palette='Set2',\n",
    "    hue_order=['rt_human', 'rt_pred'],\n",
    "    legend=True\n",
    ")\n",
    "\n",
    "# replace labels\n",
    "g._legend.set_title(None)\n",
    "g.legend.set_bbox_to_anchor((1.6, .5))\n",
    "for t, l in zip(g._legend.texts, ['Human data', 'CogPonder agent']):\n",
    "    t.set_text(l)\n",
    "\n",
    "g._legend.legend_handles[0].set_alpha(1)\n",
    "g._legend.legend_handles[1].set_alpha(1)\n",
    "\n",
    "g.ax.set(xlabel='Response Time (ms)', ylabel='# of trials')\n",
    "\n",
    "plt.suptitle('Comparing human (N=1) and CogPonder response time distributions in the Stroop task')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/figure4-stroop.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ponder')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70f45b4cee24464c60504a5fe56f777ef44c770208b66a1d7d40e1cf1ca2ecf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
