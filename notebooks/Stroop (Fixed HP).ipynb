{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CogPonder: Stroop task with fixed hyper-parameters\n",
    "\n",
    "This notebook implements the CogPonder framework using PyTorch Lightning and evaluate it on the Stroop task.\n",
    "\n",
    "\n",
    "It assumes fixed hyper-parameters and fits the model to a single-subject dataset. It wraps a simple linear network with a pondering layer and trains it on a random subject from the *Self-Regulation Ontology* dataset.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "Here, we fit the Stroop data from the *Self-Regulation Ontology*. The data is loaded from the `data/Self_Regulation_ontology/` directory; see the corresponding [README](../data/Self_Regulation_Ontology/README.md) for more information on the data structure.\n",
    "\n",
    "### Input and Output\n",
    "\n",
    "\n",
    "The input is a list of trials, including 1) the color and 2) the letter of the current stimulus. The output is the human response to the current trial (i.e., red, green, or blue), and response time.\n",
    "\n",
    "\n",
    "## Hyper-parameters\n",
    "\n",
    "- `n_embeddings`: number of hidden units in the operator model. Defaults to 8.\n",
    "- `resp_loss_beta`: the beta parameter of the loss function. Defaults to 1.\n",
    "- `time_loss_beta`: the beta parameter of the loss function. Defaults to 10.\n",
    "- `learning_rate`: the learning rate of the optimizer. Defaults to 0.001.\n",
    "- `max_response_step`: maximum response step. Defaults to the maximum response time in the dataset divided by the response_step_interval.\n",
    "- `response_step_interval`: the interval between response steps. Defaults to 10ms.\n",
    "\n",
    "## Criterion\n",
    "\n",
    "The loss function is a weighted sum of the reconstruction loss ($L_{\\text{response}}$) which measures the corss-entropy loss between human response and predicted response, and is regularized by the response time loss ($L_{\\text{time}}$), which measures the KL-div between human response times and predicted response times.\n",
    "\n",
    "$L_{\\text{total}} = \\sum pL_{\\text{response}} + \\beta L_{\\text{time}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks.progress.rich_progress import RichProgressBar\n",
    "from src.cogponder import CogPonderModel\n",
    "from src.cogponder.datasets import StroopSRODataset, CogPonderDataModule\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "TASK = 'stroop'\n",
    "\n",
    "# this notebook only fits one SRO subject, which its SRO-SubjectID can be defined here\n",
    "SRO_SUBJECT_ID = 202\n",
    "\n",
    "# number of maximum epochs to train (early stopping will be applied)\n",
    "# early stopping patience is 10% of max_epochs (min 10 epochs)\n",
    "MAX_EPOCHS = 10000\n",
    "\n",
    "# upon successful training, the trained model will be saved to this path\n",
    "CHECKPOINT_PATH = (\n",
    "    Path('models') / TASK / f'cogponder_subject-{SRO_SUBJECT_ID}_epochs-embeddings-8_{MAX_EPOCHS}.ckpt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stroop dataset... Done!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and configs\n",
    "\n",
    "print(f'Loading {TASK} dataset... ', end='')\n",
    "\n",
    "dataset = StroopSRODataset(n_subjects=-1, response_step_interval=10, non_decision_time='auto')\n",
    "data = dataset[SRO_SUBJECT_ID]\n",
    "\n",
    "# determine the number of loaded subjects\n",
    "n_subjects = data[:][0].size(1)\n",
    "\n",
    "# parameter space\n",
    "CONFIG = {\n",
    "    'task': TASK,\n",
    "    'resp_loss_beta': 1.,\n",
    "    'time_loss_beta': 10.,\n",
    "    # 'non_decision_time': 10,  # in milliseconds\n",
    "    'loss_by_trial_type': False,\n",
    "    'learning_rate': 1e-2,\n",
    "    'max_response_step': data[4].max().int().item() + 10,\n",
    "    'inputs_dim': data[0].size(1) - 1,  # minus subject_id (first column)\n",
    "    'embeddings_dim': 8,\n",
    "    'outputs_dim': torch.unique(data[3]).size(0),  # number of unique responses\n",
    "    'auto_lr_find': False,\n",
    "    'batch_size': 36,\n",
    "    'n_subjects': 1\n",
    "}\n",
    "\n",
    "datamodule = CogPonderDataModule(data,\n",
    "                                 batch_size=CONFIG['batch_size'],\n",
    "                                 num_workers=8)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # or 'mps' on Mx Macs\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": [
       "\r\u001b[2K"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BackendCompilerFailed",
     "evalue": "debug_wrapper raised CppCompileError: C++ compile error\n\nCommand:\ng++ /tmp/torchinductor_morteza/yz/cyz6yrkknrhr7r75vjmkog35o5corc7omsuvwalkj7dpvjtfae62.cpp -shared -fPIC -Wall -std=c++17 -Wno-unused-variable -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/TH -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/THC -I/usr/local/Caskroom/miniforge/base/envs/ponder2/include/python3.10 -lgomp -march=native -O3 -ffast-math -fno-finite-math-only -fopenmp -D C10_USING_CUSTOM_GENERATED_MACROS -o/tmp/torchinductor_morteza/yz/cyz6yrkknrhr7r75vjmkog35o5corc7omsuvwalkj7dpvjtfae62.so\n\nOutput:\nclang: error: unsupported option '-fopenmp'\nclang: error: unsupported option '-fopenmp'\n\n\nSet torch._dynamo.config.verbose=True for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/codecache.py:436\u001b[0m, in \u001b[0;36mCppCodeCache.load\u001b[0;34m(cls, source_code)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 436\u001b[0m     subprocess\u001b[39m.\u001b[39;49mcheck_output(cmd, stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mSTDOUT)\n\u001b[1;32m    437\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/subprocess.py:421\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[0;32m--> 421\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39;49mpopenargs, stdout\u001b[39m=\u001b[39;49mPIPE, timeout\u001b[39m=\u001b[39;49mtimeout, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    422\u001b[0m            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[39mif\u001b[39;00m check \u001b[39mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[39mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[39m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m CompletedProcess(process\u001b[39m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['g++', '/tmp/torchinductor_morteza/yz/cyz6yrkknrhr7r75vjmkog35o5corc7omsuvwalkj7dpvjtfae62.cpp', '-shared', '-fPIC', '-Wall', '-std=c++17', '-Wno-unused-variable', '-I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include', '-I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/torch/csrc/api/include', '-I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/TH', '-I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/THC', '-I/usr/local/Caskroom/miniforge/base/envs/ponder2/include/python3.10', '-lgomp', '-march=native', '-O3', '-ffast-math', '-fno-finite-math-only', '-fopenmp', '-D', 'C10_USING_CUSTOM_GENERATED_MACROS', '-o/tmp/torchinductor_morteza/yz/cyz6yrkknrhr7r75vjmkog35o5corc7omsuvwalkj7dpvjtfae62.so']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCppCompileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:675\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 675\u001b[0m     compiled_fn \u001b[39m=\u001b[39m compiler_fn(gm, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfake_example_inputs())\n\u001b[1;32m    676\u001b[0m _step_logger()(logging\u001b[39m.\u001b[39mINFO, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdone compiler function \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py:934\u001b[0m, in \u001b[0;36mwrap_backend_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 934\u001b[0m     compiled_gm \u001b[39m=\u001b[39m compiler_fn(gm, example_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    936\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_gm\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/__init__.py:1153\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.__call__\u001b[0;34m(self, model_, inputs_)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcm:\n\u001b[0;32m-> 1153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_fn(model_, inputs_)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:398\u001b[0m, in \u001b[0;36mcompile_fx\u001b[0;34m(model_, example_inputs_, inner_compile)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39mwith\u001b[39;00m overrides\u001b[39m.\u001b[39mpatch_functions():\n\u001b[1;32m    394\u001b[0m \n\u001b[1;32m    395\u001b[0m     \u001b[39m# TODO: can add logging before/after the call to create_aot_dispatcher_function\u001b[39;00m\n\u001b[1;32m    396\u001b[0m     \u001b[39m# in torch._functorch/aot_autograd.py::aot_module_simplified::aot_function_simplified::new_func\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[39m# once torchdynamo is merged into pytorch\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mreturn\u001b[39;00m aot_autograd(\n\u001b[1;32m    399\u001b[0m         fw_compiler\u001b[39m=\u001b[39;49mfw_compiler,\n\u001b[1;32m    400\u001b[0m         bw_compiler\u001b[39m=\u001b[39;49mbw_compiler,\n\u001b[1;32m    401\u001b[0m         decompositions\u001b[39m=\u001b[39;49mselect_decomp_table(),\n\u001b[1;32m    402\u001b[0m         partition_fn\u001b[39m=\u001b[39;49mfunctools\u001b[39m.\u001b[39;49mpartial(\n\u001b[1;32m    403\u001b[0m             min_cut_rematerialization_partition, compiler\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minductor\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    404\u001b[0m         ),\n\u001b[1;32m    405\u001b[0m     )(model_, example_inputs_)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/optimizations/training.py:78\u001b[0m, in \u001b[0;36maot_autograd.<locals>.compiler_fn\u001b[0;34m(gm, example_inputs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mwith\u001b[39;00m enable_aot_logging():\n\u001b[0;32m---> 78\u001b[0m     cg \u001b[39m=\u001b[39m aot_module_simplified(gm, example_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     79\u001b[0m     counters[\u001b[39m\"\u001b[39m\u001b[39maot_autograd\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mok\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2342\u001b[0m, in \u001b[0;36maot_module_simplified\u001b[0;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, hasher_type, static_argnums)\u001b[0m\n\u001b[1;32m   2340\u001b[0m full_args\u001b[39m.\u001b[39mextend(args)\n\u001b[0;32m-> 2342\u001b[0m compiled_fn \u001b[39m=\u001b[39m create_aot_dispatcher_function(\n\u001b[1;32m   2343\u001b[0m     functional_call,\n\u001b[1;32m   2344\u001b[0m     full_args,\n\u001b[1;32m   2345\u001b[0m     aot_config,\n\u001b[1;32m   2346\u001b[0m )\n\u001b[1;32m   2348\u001b[0m \u001b[39m# TODO: There is something deeply wrong here; compiled_fn running with\u001b[39;00m\n\u001b[1;32m   2349\u001b[0m \u001b[39m# the boxed calling convention, but aot_module_simplified somehow\u001b[39;00m\n\u001b[1;32m   2350\u001b[0m \u001b[39m# historically returned a function that was not the boxed calling\u001b[39;00m\n\u001b[1;32m   2351\u001b[0m \u001b[39m# convention.  This should get fixed...\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/utils.py:90\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 90\u001b[0m r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     91\u001b[0m latency \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2039\u001b[0m, in \u001b[0;36mcreate_aot_dispatcher_function\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   2037\u001b[0m \u001b[39m# You can put more passes here\u001b[39;00m\n\u001b[0;32m-> 2039\u001b[0m compiled_fn \u001b[39m=\u001b[39m compiler_fn(flat_fn, fake_flat_tensor_args, aot_config)\n\u001b[1;32m   2041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(compiled_fn, \u001b[39m'\u001b[39m\u001b[39m_boxed_call\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1304\u001b[0m, in \u001b[0;36maot_wrapper_dedupe\u001b[0;34m(flat_fn, flat_args, aot_config, compiler_fn)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[39mif\u001b[39;00m ok:\n\u001b[0;32m-> 1304\u001b[0m         \u001b[39mreturn\u001b[39;00m compiler_fn(flat_fn, leaf_flat_args, aot_config)\n\u001b[1;32m   1306\u001b[0m \u001b[39m# Strategy 2: Duplicate specialize.\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[39m# In Haskell types, suppose you have:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[39m#   }\u001b[39;00m\n\u001b[1;32m   1341\u001b[0m \u001b[39m#   keep_arg_mask = [True, True, False, True]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:954\u001b[0m, in \u001b[0;36maot_dispatch_base\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39mwith\u001b[39;00m context(), track_graph_compiling(aot_config, \u001b[39m\"\u001b[39m\u001b[39minference\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 954\u001b[0m     compiled_fw \u001b[39m=\u001b[39m aot_config\u001b[39m.\u001b[39;49mfw_compiler(fw_module, flat_args)\n\u001b[1;32m    956\u001b[0m \u001b[39m@wraps\u001b[39m(compiled_fw)\n\u001b[1;32m    957\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_fn\u001b[39m(args):\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/utils.py:90\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 90\u001b[0m r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     91\u001b[0m latency \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:373\u001b[0m, in \u001b[0;36mcompile_fx.<locals>.fw_compiler\u001b[0;34m(model, example_inputs)\u001b[0m\n\u001b[1;32m    372\u001b[0m fixed \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(example_inputs) \u001b[39m-\u001b[39m num_example_inputs\n\u001b[0;32m--> 373\u001b[0m \u001b[39mreturn\u001b[39;00m inner_compile(\n\u001b[1;32m    374\u001b[0m     model,\n\u001b[1;32m    375\u001b[0m     example_inputs,\n\u001b[1;32m    376\u001b[0m     num_fixed\u001b[39m=\u001b[39;49mfixed,\n\u001b[1;32m    377\u001b[0m     cudagraphs\u001b[39m=\u001b[39;49mcudagraphs,\n\u001b[1;32m    378\u001b[0m     graph_id\u001b[39m=\u001b[39;49mgraph_id,\n\u001b[1;32m    379\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py:507\u001b[0m, in \u001b[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m     compiled_fn \u001b[39m=\u001b[39m compiler_fn(gm, example_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    509\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fn\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/debug.py:223\u001b[0m, in \u001b[0;36mDebugContext.wrap.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mwith\u001b[39;00m DebugContext():\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:140\u001b[0m, in \u001b[0;36mcompile_fx_inner\u001b[0;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id)\u001b[0m\n\u001b[1;32m    139\u001b[0m     graph\u001b[39m.\u001b[39mrun(\u001b[39m*\u001b[39mexample_inputs)\n\u001b[0;32m--> 140\u001b[0m     compiled_fn \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39;49mcompile_to_fn()\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m cudagraphs:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/graph.py:519\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile_to_fn\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_to_module()\u001b[39m.\u001b[39mcall\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/utils.py:90\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 90\u001b[0m r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     91\u001b[0m latency \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/graph.py:508\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[39mprint\u001b[39m(code)\n\u001b[0;32m--> 508\u001b[0m mod \u001b[39m=\u001b[39m PyCodeCache\u001b[39m.\u001b[39;49mload(code)\n\u001b[1;32m    509\u001b[0m \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstants\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/codecache.py:459\u001b[0m, in \u001b[0;36mPyCodeCache.load\u001b[0;34m(cls, source_code)\u001b[0m\n\u001b[1;32m    458\u001b[0m mod\u001b[39m.\u001b[39mkey \u001b[39m=\u001b[39m key\n\u001b[0;32m--> 459\u001b[0m exec(code, mod\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m, mod\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m)\n\u001b[1;32m    460\u001b[0m \u001b[39m# another thread might set this first\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/torchinductor_morteza/pv/cpvngfia66fdwl6hm4opokdn4ba4lvpiwue4vpnrikz33cbqhvhw.py:37\u001b[0m\n\u001b[1;32m     13\u001b[0m kernel_cpp_0 \u001b[39m=\u001b[39m async_compile\u001b[39m.\u001b[39mcpp(\u001b[39m'''\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[39m#include \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/tmp/torchinductor_morteza/77/c7773nj5pwikpmm2pwa62rcudlf7p3if7eyqb5k4sjsvewwje4le.h\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[39mextern \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m void kernel(const signed char* __restrict__ in_ptr0,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m}\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[39m'''\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m async_compile\u001b[39m.\u001b[39;49mwait(\u001b[39mglobals\u001b[39;49m())\n\u001b[1;32m     38\u001b[0m \u001b[39mdel\u001b[39;00m async_compile\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/codecache.py:639\u001b[0m, in \u001b[0;36mAsyncCompile.wait\u001b[0;34m(self, scope)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, (Future, TritonFuture)):\n\u001b[0;32m--> 639\u001b[0m             scope[key] \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    641\u001b[0m _compile_end()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/codecache.py:631\u001b[0m, in \u001b[0;36mAsyncCompile.cpp.<locals>.task\u001b[0;34m()\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtask\u001b[39m():\n\u001b[0;32m--> 631\u001b[0m     \u001b[39mreturn\u001b[39;00m CppCodeCache\u001b[39m.\u001b[39;49mload(source_code)\u001b[39m.\u001b[39mkernel\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_inductor/codecache.py:438\u001b[0m, in \u001b[0;36mCppCodeCache.load\u001b[0;34m(cls, source_code)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 438\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mCppCompileError(cmd, e\u001b[39m.\u001b[39moutput) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcache[key] \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_load_library(output_path)\n",
      "\u001b[0;31mCppCompileError\u001b[0m: C++ compile error\n\nCommand:\ng++ /tmp/torchinductor_morteza/yz/cyz6yrkknrhr7r75vjmkog35o5corc7omsuvwalkj7dpvjtfae62.cpp -shared -fPIC -Wall -std=c++17 -Wno-unused-variable -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/TH -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/THC -I/usr/local/Caskroom/miniforge/base/envs/ponder2/include/python3.10 -lgomp -march=native -O3 -ffast-math -fno-finite-math-only -fopenmp -D C10_USING_CUSTOM_GENERATED_MACROS -o/tmp/torchinductor_morteza/yz/cyz6yrkknrhr7r75vjmkog35o5corc7omsuvwalkj7dpvjtfae62.so\n\nOutput:\nclang: error: unsupported option '-fopenmp'\nclang: error: unsupported option '-fopenmp'\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBackendCompilerFailed\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     trainer\u001b[39m.\u001b[39mtune(model, datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[1;32m     28\u001b[0m \u001b[39m# Fit and evaluate the model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, datamodule\u001b[39m=\u001b[39;49mdatamodule)\n\u001b[1;32m     31\u001b[0m \u001b[39m# Save the latest checkpoint\u001b[39;00m\n\u001b[1;32m     32\u001b[0m trainer\u001b[39m.\u001b[39msave_checkpoint(CHECKPOINT_PATH)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:603\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 603\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    604\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    605\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:645\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    638\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    641\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    643\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    644\u001b[0m )\n\u001b[0;32m--> 645\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    647\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    648\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1098\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1096\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1098\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1100\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1177\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1176\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1177\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1190\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1189\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1192\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1262\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> 1262\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1266\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    151\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 152\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    154\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    136\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    138\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m    the outputs of the step\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 234\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(hook_name, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1480\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1480\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1482\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[1;32m    389\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:212\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    211\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    213\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:333\u001b[0m, in \u001b[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001b[0;34m(frame, cache_size)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[39mreturn\u001b[39;00m hijacked_callback(frame, cache_size, hooks)\n\u001b[1;32m    332\u001b[0m \u001b[39mwith\u001b[39;00m compile_lock:\n\u001b[0;32m--> 333\u001b[0m     \u001b[39mreturn\u001b[39;00m callback(frame, cache_size, hooks)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:480\u001b[0m, in \u001b[0;36mconvert_frame.<locals>._convert_frame\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    478\u001b[0m counters[\u001b[39m\"\u001b[39m\u001b[39mframes\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    479\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m     result \u001b[39m=\u001b[39m inner_convert(frame, cache_size, hooks)\n\u001b[1;32m    481\u001b[0m     counters[\u001b[39m\"\u001b[39m\u001b[39mframes\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mok\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:103\u001b[0m, in \u001b[0;36mwrap_convert_context.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m torch\u001b[39m.\u001b[39mfx\u001b[39m.\u001b[39mgraph_module\u001b[39m.\u001b[39m_forward_from_src \u001b[39m=\u001b[39m fx_forward_from_src_skip_result\n\u001b[1;32m    102\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    104\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_set_grad_enabled(prior_grad_mode)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/utils.py:90\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     compilation_metrics[key] \u001b[39m=\u001b[39m []\n\u001b[1;32m     89\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 90\u001b[0m r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     91\u001b[0m latency \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[1;32m     92\u001b[0m \u001b[39m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:339\u001b[0m, in \u001b[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mglobal\u001b[39;00m initial_grad_state\n\u001b[1;32m    337\u001b[0m initial_grad_state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_grad_enabled()\n\u001b[0;32m--> 339\u001b[0m \u001b[39mreturn\u001b[39;00m _compile(\n\u001b[1;32m    340\u001b[0m     frame\u001b[39m.\u001b[39;49mf_code,\n\u001b[1;32m    341\u001b[0m     frame\u001b[39m.\u001b[39;49mf_globals,\n\u001b[1;32m    342\u001b[0m     frame\u001b[39m.\u001b[39;49mf_locals,\n\u001b[1;32m    343\u001b[0m     frame\u001b[39m.\u001b[39;49mf_builtins,\n\u001b[1;32m    344\u001b[0m     compiler_fn,\n\u001b[1;32m    345\u001b[0m     one_graph,\n\u001b[1;32m    346\u001b[0m     export,\n\u001b[1;32m    347\u001b[0m     hooks,\n\u001b[1;32m    348\u001b[0m     frame,\n\u001b[1;32m    349\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:400\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[39mfor\u001b[39;00m attempt \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mcount():\n\u001b[1;32m    399\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m         out_code \u001b[39m=\u001b[39m transform_code_object(code, transform)\n\u001b[1;32m    401\u001b[0m         orig_code_map[out_code] \u001b[39m=\u001b[39m code\n\u001b[1;32m    402\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:341\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m    338\u001b[0m instructions \u001b[39m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[1;32m    339\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m--> 341\u001b[0m transformations(instructions, code_options)\n\u001b[1;32m    343\u001b[0m fix_vars(instructions, code_options)\n\u001b[1;32m    345\u001b[0m dirty \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:387\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mnonlocal\u001b[39;00m output\n\u001b[1;32m    375\u001b[0m tracer \u001b[39m=\u001b[39m InstructionTranslator(\n\u001b[1;32m    376\u001b[0m     instructions,\n\u001b[1;32m    377\u001b[0m     code,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m     mutated_closure_cell_contents,\n\u001b[1;32m    386\u001b[0m )\n\u001b[0;32m--> 387\u001b[0m tracer\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m    388\u001b[0m output \u001b[39m=\u001b[39m tracer\u001b[39m.\u001b[39moutput\n\u001b[1;32m    389\u001b[0m \u001b[39massert\u001b[39;00m output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1684\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1683\u001b[0m     _step_logger()(logging\u001b[39m.\u001b[39mINFO, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorchdynamo start tracing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_code\u001b[39m.\u001b[39mco_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1684\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:538\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39mpush_tx(\u001b[39mself\u001b[39m)\n\u001b[1;32m    535\u001b[0m     \u001b[39mwhile\u001b[39;00m (\n\u001b[1;32m    536\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstruction_pointer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    537\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39mshould_exit\n\u001b[0;32m--> 538\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    539\u001b[0m     ):\n\u001b[1;32m    540\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:501\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, inst\u001b[39m.\u001b[39mopname):\n\u001b[1;32m    500\u001b[0m         unimplemented(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmissing: \u001b[39m\u001b[39m{\u001b[39;00minst\u001b[39m.\u001b[39mopname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, inst\u001b[39m.\u001b[39;49mopname)(inst)\n\u001b[1;32m    503\u001b[0m     \u001b[39mreturn\u001b[39;00m inst\u001b[39m.\u001b[39mopname \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRETURN_VALUE\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m \u001b[39mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:337\u001b[0m, in \u001b[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    335\u001b[0m     reason \u001b[39m=\u001b[39m GraphCompileReason(excp\u001b[39m.\u001b[39mmsg, user_stack)\n\u001b[1;32m    336\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestore_graphstate(state)\n\u001b[0;32m--> 337\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput\u001b[39m.\u001b[39;49mcompile_subgraph(\u001b[39mself\u001b[39;49m, reason\u001b[39m=\u001b[39;49mreason)\n\u001b[1;32m    338\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpopn(push \u001b[39m-\u001b[39m dis\u001b[39m.\u001b[39mstack_effect(inst\u001b[39m.\u001b[39mopcode, inst\u001b[39m.\u001b[39marg))\n\u001b[1;32m    340\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(push):\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:551\u001b[0m, in \u001b[0;36mOutputGraph.compile_subgraph\u001b[0;34m(self, tx, partial_convert, reason)\u001b[0m\n\u001b[1;32m    548\u001b[0m output \u001b[39m=\u001b[39m []\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m count_calls(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(pass2\u001b[39m.\u001b[39mgraph_outputs) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    550\u001b[0m     output\u001b[39m.\u001b[39mextend(\n\u001b[0;32m--> 551\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_and_call_fx_graph(tx, pass2\u001b[39m.\u001b[39;49mgraph_output_vars(), root)\n\u001b[1;32m    552\u001b[0m     )\n\u001b[1;32m    554\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(pass2\u001b[39m.\u001b[39mgraph_outputs) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    555\u001b[0m         output\u001b[39m.\u001b[39mappend(pass2\u001b[39m.\u001b[39mcreate_store(graph_output_var))\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:599\u001b[0m, in \u001b[0;36mOutputGraph.compile_and_call_fx_graph\u001b[0;34m(self, tx, rv, root)\u001b[0m\n\u001b[1;32m    597\u001b[0m assert_no_fake_params_or_buffers(gm)\n\u001b[1;32m    598\u001b[0m \u001b[39mwith\u001b[39;00m tracing(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracing_context):\n\u001b[0;32m--> 599\u001b[0m     compiled_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_user_compiler(gm)\n\u001b[1;32m    600\u001b[0m compiled_fn \u001b[39m=\u001b[39m disable(compiled_fn)\n\u001b[1;32m    602\u001b[0m counters[\u001b[39m\"\u001b[39m\u001b[39mstats\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39munique_graphs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:680\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    679\u001b[0m     compiled_fn \u001b[39m=\u001b[39m gm\u001b[39m.\u001b[39mforward\n\u001b[0;32m--> 680\u001b[0m     \u001b[39mraise\u001b[39;00m BackendCompilerFailed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiler_fn, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[0;31mBackendCompilerFailed\u001b[0m: debug_wrapper raised CppCompileError: C++ compile error\n\nCommand:\ng++ /tmp/torchinductor_morteza/yz/cyz6yrkknrhr7r75vjmkog35o5corc7omsuvwalkj7dpvjtfae62.cpp -shared -fPIC -Wall -std=c++17 -Wno-unused-variable -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/TH -I/usr/local/Caskroom/miniforge/base/envs/ponder2/lib/python3.10/site-packages/torch/include/THC -I/usr/local/Caskroom/miniforge/base/envs/ponder2/include/python3.10 -lgomp -march=native -O3 -ffast-math -fno-finite-math-only -fopenmp -D C10_USING_CUSTOM_GENERATED_MACROS -o/tmp/torchinductor_morteza/yz/cyz6yrkknrhr7r75vjmkog35o5corc7omsuvwalkj7dpvjtfae62.so\n\nOutput:\nclang: error: unsupported option '-fopenmp'\nclang: error: unsupported option '-fopenmp'\n\n\nSet torch._dynamo.config.verbose=True for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "# Define the pondering model and run the trainer\n",
    "\n",
    "model = CogPonderModel(CONFIG)#, example_input_array=data[0][:1].to(device))\n",
    "\n",
    "# TODO: check if torch>=2.0 is installed\n",
    "# model = torch.compile(model)\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    # min_epochs=100,\n",
    "    accelerator='auto',\n",
    "    auto_lr_find=CONFIG['auto_lr_find'],\n",
    "    log_every_n_steps=1,\n",
    "    # overfit_batches=True,\n",
    "    # accumulate_grad_batches=2,\n",
    "    callbacks=[\n",
    "        RichProgressBar(),\n",
    "        EarlyStopping(monitor='val/total_loss',\n",
    "                      patience=np.max([10, MAX_EPOCHS // 10]).item(),\n",
    "                      mode='min', min_delta=0.001),\n",
    "    ])\n",
    "\n",
    "# Auto-detect learning-rate if the flag is set\n",
    "if CONFIG['auto_lr_find']:\n",
    "    trainer.tune(model, datamodule=datamodule)\n",
    "\n",
    "# Fit and evaluate the model\n",
    "trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "# Save the latest checkpoint\n",
    "trainer.save_checkpoint(CHECKPOINT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "\n",
    "# DEBUG - Load the checkpoint\n",
    "\n",
    "model_ckpt = CogPonderModel.load_from_checkpoint(CHECKPOINT_PATH)\n",
    "model_ckpt.eval()\n",
    "\n",
    "# reload the data module if it is not loaded yet\n",
    "if not 'datamodule' in locals() or not hasattr(datamodule, 'train_dataset'):\n",
    "    print('loading data module...', end='')\n",
    "    data = StroopSRODataset(n_subjects=-1, response_step_interval=10)[SRO_SUBJECT_ID]\n",
    "    datamodule = CogPonderDataModule(data, batch_size=CONFIG['batch_size'], num_workers=8)\n",
    "    datamodule.prepare_data()\n",
    "    print('Done!')\n",
    "\n",
    "X_train, trial_types_train, is_corrects_train, y_train, rt_train = datamodule.train_dataset[:]\n",
    "X_test, trial_types_test, is_corrects_test, y_test, rt_test = datamodule.test_dataset[:]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_ckpt.eval()\n",
    "\n",
    "    y_train_steps,p_train,rt_train_pred = model_ckpt(X_train)\n",
    "    y_test_steps,p_test,rt_test_pred = model_ckpt(X_test)\n",
    "\n",
    "    y_train_steps = torch.argmax(y_train_steps, dim=-1)\n",
    "    y_test_steps = torch.argmax(y_test_steps, dim=-1)\n",
    "\n",
    "    y_train_pred = y_train_steps.gather(dim=0, index=rt_train_pred[None, :] - 1,)[0]  # (batch_size,)\n",
    "    y_test_pred = y_test_steps.gather(dim=0, index=rt_test_pred[None, :] - 1,)[0]  # (batch_size,)\n",
    "\n",
    "    train_res = pd.DataFrame({'true_rt_train': rt_train.detach().tolist(),\n",
    "                              'pred_rt_train': rt_train_pred.tolist()})\n",
    "    test_res = pd.DataFrame({'true_rt_test': rt_test.detach().tolist(),\n",
    "                             'pred_rt_test': rt_test_pred.tolist()})\n",
    "\n",
    "    display(train_res.T, test_res.T)\n",
    "\n",
    "    # report Stroop accuracy\n",
    "    is_corrects_pred = (y_test_pred.long() == y_test).float()\n",
    "    cong_is_corrects = torch.where(trial_types_test == 1, is_corrects_pred, torch.nan)\n",
    "    incong_is_corrects = torch.where(trial_types_test == 0, is_corrects_pred, torch.nan)\n",
    "\n",
    "    accuracy = torch.nanmean(is_corrects_pred)\n",
    "    cong_accuracy = torch.nanmean(cong_is_corrects)\n",
    "    incong_accuracy = torch.nanmean(incong_is_corrects)\n",
    "\n",
    "    print(TASK, '%correct (total / congruent / incongruent): {:.3f} / {:.3f} / {:.3f}'.format(\n",
    "            accuracy.item(), cong_accuracy.item(), incong_accuracy.item()))\n",
    "\n",
    "# DEBUG report mean-RT\n",
    "print(f'RT train mean (pred/true): '\n",
    "      f'{rt_train_pred.float().mean().item():.2f}, '\n",
    "      f'{rt_train.float().mean().item():.2f}')\n",
    "\n",
    "print(f'RT test  mean (pred/true): '\n",
    "      f'{rt_test_pred.float().mean().item():.2f}, '\n",
    "      f'{rt_test.float().mean().item():.2f}')\n",
    "\n",
    "# DEBUG - report sd-RT\n",
    "print(f'RT train std (pred/true): '\n",
    "      f'{rt_train_pred.float().std().item():.2f}, '\n",
    "      f'{rt_train.float().std().item():.2f}')\n",
    "\n",
    "print(f'RT test  std (pred/true): '\n",
    "      f'{rt_test_pred.float().std().item():.2f}, '\n",
    "      f'{rt_test.float().std().item():.2f}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the predicted response time distributions per condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# prepare plotting data\n",
    "\n",
    "plot_data_train = pd.DataFrame({\n",
    "    'rt': rt_train,\n",
    "    'trial_type': trial_types_train,\n",
    "    'color': X_train[:, 0],\n",
    "    'word': X_train[:, 1],\n",
    "    'data': 'truth',\n",
    "    'split': 'train',\n",
    "})\n",
    "\n",
    "plot_data_train_pred = pd.DataFrame({\n",
    "    'rt': rt_train_pred,\n",
    "    'trial_type': trial_types_train,\n",
    "    'color': X_train[:, 0],\n",
    "    'word': X_train[:, 1],\n",
    "    'data': 'pred',\n",
    "    'split': 'train',\n",
    "})\n",
    "\n",
    "plot_data_test = pd.DataFrame({\n",
    "    'rt': rt_test,\n",
    "    'trial_type': trial_types_test,\n",
    "    'color': X_test[:, 0],\n",
    "    'word': X_test[:, 1],\n",
    "    'data': 'truth',\n",
    "    'split': 'test',\n",
    "})\n",
    "\n",
    "plot_data_test_pred = pd.DataFrame({\n",
    "    'rt': rt_test_pred,\n",
    "    'trial_type': trial_types_test,\n",
    "    'color': X_test[:, 0],\n",
    "    'word': X_test[:, 1],\n",
    "    'data': 'pred',\n",
    "    'split': 'test',\n",
    "})\n",
    "\n",
    "# merge and cleanup\n",
    "plot_data = pd.concat([plot_data_train, plot_data_train_pred, plot_data_test, plot_data_test_pred])\n",
    "plot_data['trial_type'] = plot_data['trial_type'].map({0: 'incongruent', 1: 'congruent'})\n",
    "\n",
    "max_rt = CONFIG[\"max_response_step\"]\n",
    "\n",
    "plot_data = plot_data.query('rt < @max_rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "g = sns.displot(\n",
    "    plot_data,\n",
    "    x='rt', row='data', col='split', hue='trial_type',\n",
    "    kind='ecdf', linewidth=2, height=3,\n",
    ")\n",
    "\n",
    "sns.move_legend(g, 'upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "# plt.title(f'Evaluation profile of CogPonder on train split (Stroop)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the overall predicted response time distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.displot(\n",
    "    plot_data.reset_index(),\n",
    "    x='rt', row='data', col='split', #hue='trial_type',\n",
    "    kind='hist', height=3, #palette='Greens',\n",
    "    kde=True, kde_kws={'clip': (0, max_rt)},\n",
    "    facet_kws={'sharey': False}\n",
    ")\n",
    "# sns.move_legend(g, 'upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "# plt.title(f'Evaluation profile of CogPonder on train split (Stroop)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ponder2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b1be41b01f2cd74603ebe49a53b70aa2bdf69773a47de21b61e4a157687cce6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
