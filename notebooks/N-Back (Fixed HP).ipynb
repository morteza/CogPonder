{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CogPonder: Stroop Task with Fixed Hyper-parameters\n",
    "\n",
    "This notebook implements the CogPonder algorithm using PyTorch Lightning to perfrom the Stroop task. It assumes fixed hyper-parameters and fits the model to a single-subject dataset. It wraps a simple linear network with a pondering layer and trains it on the *Self-Regulation Ontology* dataset.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "Here, we fit the Stroop data from the *Self-Regulation Ontology*. The data is loaded from the `data/Self_Regulation_ontology/` directory. See the `data/Self_Regulation_ontology/README.md` file for more information.\n",
    "\n",
    "### Input and Output\n",
    "\n",
    "#### Stroop\n",
    "\n",
    "The input is the 1) color and 2) letter of the current stimuli. The output is the human response to the current trial (red, green, or blue).\n",
    "\n",
    "\n",
    "#### N-Back\n",
    "\n",
    "Previous N+1 presented symbols are used as input, the last input is the current symbol. The output is the human response to the N+1th trial.\n",
    "\n",
    "\n",
    "## Hyper-parameters\n",
    "\n",
    "- `n_embeddings`: number of hidden units in the operator model. Defaults to $N_{\\text{symbols} + 1}$\n",
    "- `rec_loss_beta`: the beta parameter of the loss function. Defaults to 0.5.\n",
    "- `cog_loss_beta`: the beta parameter of the loss function. Defaults to 0.5.\n",
    "- `learning_rate`: the learning rate of the optimizer. Defaults to 0.0001.\n",
    "- `max_response_step`: maximum response step in the dataset. Defaults to $\\max(\\text{response\\_step}) + 10$.\n",
    "\n",
    "## Criterion\n",
    "\n",
    "$L = L_{\\text{reconstruction}} + L_{\\text{cognitive}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks.progress.rich_progress import RichProgressBar\n",
    "from src.cogponder import CogPonderModel\n",
    "from src.cogponder.datasets import NBackSRODataset, CogPonderDataModule\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook only fits one SRO subject, which its SRO-SubjectID can be defined here\n",
    "SRO_SUBJECT_ID = 202\n",
    "\n",
    "# number of maximum epochs to train\n",
    "MAX_EPOCHS = 10000\n",
    "\n",
    "# upon successful training, the model will be saved to this path\n",
    "CHECKPOINT_PATH = Path('models/nback/') / f'cogponder_subject-{SRO_SUBJECT_ID}_epochs-{MAX_EPOCHS}.ckpt'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading N-Back dataset... Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and configs\n",
    "\n",
    "print('Loading N-Back dataset... ', end='')\n",
    "\n",
    "dataset = NBackSRODataset(n_subjects=-1, response_step_interval=10, non_decision_time='auto')\n",
    "data = dataset[0]\n",
    "\n",
    "# determine the number of loaded subjects\n",
    "n_subjects = data[0].size(1)\n",
    "\n",
    "\n",
    "n_symbols = torch.unique(data[0]).shape[0]\n",
    "\n",
    "# parameter space\n",
    "CONFIG = {\n",
    "    'task': 'nback',\n",
    "    'resp_loss_beta': 1.,\n",
    "    'time_loss_beta': 10.,\n",
    "    # 'non_decision_time': 10,  # in milliseconds\n",
    "    'loss_by_trial_type': False,\n",
    "    'learning_rate': 1e-2,\n",
    "    'max_response_step': data[4].max().int().item() + 10,\n",
    "    'inputs_dim': data[0].size(1) - 1,  # minus subject_id (first column)\n",
    "    'embeddings_dim': n_symbols,\n",
    "    'outputs_dim': torch.unique(data[3]).size(0),  # number of unique responses\n",
    "    'auto_lr_find': False,\n",
    "    'batch_size': 72,\n",
    "    'n_subjects': 1\n",
    "}\n",
    "\n",
    "datamodule = CogPonderDataModule(data,\n",
    "                                 batch_size=CONFIG['batch_size'],\n",
    "                                 num_workers=8)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name           </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         In sizes </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Out sizes </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ train_accuracy │ Accuracy           │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">         ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ val_accuracy   │ Accuracy           │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">         ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ cog_loss_fn    │ CognitiveLoss      │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">         ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ rec_loss_fn    │ ReconstructionLoss │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">         ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ halt_node      │ Sequential         │      9 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">           [1, 2] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    [1, 1] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ output_node    │ Sequential         │     15 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">           [1, 2] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    [1, 3] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ recurrent_node │ GRUCell            │     36 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [[1, 2], [1, 2]] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    [1, 2] </span>│\n",
       "└───┴────────────────┴────────────────────┴────────┴──────────────────┴───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName          \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m        In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mOut sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ train_accuracy │ Accuracy           │      0 │\u001b[37m \u001b[0m\u001b[37m               ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m        ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ val_accuracy   │ Accuracy           │      0 │\u001b[37m \u001b[0m\u001b[37m               ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m        ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ cog_loss_fn    │ CognitiveLoss      │      0 │\u001b[37m \u001b[0m\u001b[37m               ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m        ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ rec_loss_fn    │ ReconstructionLoss │      0 │\u001b[37m \u001b[0m\u001b[37m               ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m        ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ halt_node      │ Sequential         │      9 │\u001b[37m \u001b[0m\u001b[37m          [1, 2]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m   [1, 1]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ output_node    │ Sequential         │     15 │\u001b[37m \u001b[0m\u001b[37m          [1, 2]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m   [1, 3]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ recurrent_node │ GRUCell            │     36 │\u001b[37m \u001b[0m\u001b[37m[[1, 2], [1, 2]]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m   [1, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "└───┴────────────────┴────────────────────┴────────┴──────────────────┴───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 60                                                                                               \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 60                                                                                                   \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 60                                                                                               \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 60                                                                                                   \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e589f5e9eb274cd4a767c6238126bcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/morteza/mambaforge/envs/ponder/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connect\n",
       "or.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this\n",
       "machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/morteza/mambaforge/envs/ponder/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connect\n",
       "or.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this\n",
       "machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/morteza/mambaforge/envs/ponder/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connect\n",
       "or.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this\n",
       "machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/morteza/mambaforge/envs/ponder/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connect\n",
       "or.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this\n",
       "machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the pondering model and run the trainer\n",
    "\n",
    "model = CogPonderModel(CONFIG)#, example_input_array=data[0][:1].to(device))\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    # min_epochs=100,\n",
    "    accelerator='auto',\n",
    "    auto_lr_find=CONFIG['auto_lr_find'],\n",
    "    log_every_n_steps=1,\n",
    "    # overfit_batches=True,\n",
    "    # accumulate_grad_batches=2,\n",
    "    callbacks=[\n",
    "        RichProgressBar(),\n",
    "        EarlyStopping(monitor='val/total_loss',\n",
    "                      patience=np.max([10, MAX_EPOCHS // 10]).item(),\n",
    "                      mode='min', min_delta=0.001),\n",
    "    ])\n",
    "\n",
    "# Auto-detect learning-rate if the flag is set\n",
    "if CONFIG['auto_lr_find']:\n",
    "    trainer.tune(model, datamodule=datamodule)\n",
    "\n",
    "# Fit and evaluate the model\n",
    "trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "# Save the latest checkpoint\n",
    "trainer.save_checkpoint(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "RT TRUE TRAIN: [54, 30, 32, 44, 35, 45, 33, 38, 33, 63, 45, 38, 38, 30, 38, 26, 25, 31, 47, 37, 44, 49, 44, 39, 50, 37, 46, 51, 37, 44, 54, 34, 42, 54, 36, 45, 44, 43, 41, 51, 30, 69, 51, 43, 39, 31, 47, 32, 32, 25, 60, 45, 46, 45, 52, 53, 59, 57, 47, 52, 42, 50, 32, 26, 23, 24, 44, 28, 49, 48, 39] \n",
      "RT PRED TRAIN: [54, 18, 92, 84, 100, 5, 49, 61, 44, 100, 45, 46, 93, 18, 16, 19, 4, 100, 100, 45, 100, 84, 46, 23, 6, 100, 72, 26, 39, 46, 45, 15, 46, 43, 32, 46, 5, 91, 46, 16, 100, 11, 45, 48, 29, 69, 46, 46, 13, 17, 47, 55, 44, 8, 47, 9, 45, 66, 10, 62, 57, 45, 46, 46, 49, 45, 28, 78, 100, 17, 20]\n",
      "RT TRUE TEST: [34, 35, 57, 31, 29, 39, 66, 49, 31, 73, 67, 41, 38, 44, 33, 72, 47, 40, 56, 36, 66, 37, 46, 29] \n",
      "RT PRED TEST: [55, 47, 51, 21, 100, 46, 92, 48, 48, 48, 18, 46, 45, 74, 100, 46, 58, 49, 49, 13, 100, 78, 13, 48]\n",
      "RT mean (pred/true):  47.43661880493164 41.78873062133789\n",
      "RT mean (pred/true):  53.875 45.66666793823242\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# DEBUG - Load the checkpoint\n",
    "\n",
    "model_ckpt = CogPonderModel.load_from_checkpoint(CHECKPOINT_PATH)\n",
    "model_ckpt.eval()\n",
    "\n",
    "if not 'datamodule' in locals() or not hasattr(datamodule, 'train_dataset'):\n",
    "    print('loading N-back dataset...', end='')\n",
    "    data = NBackSRODataset(n_subjects=-1, response_step_interval=10)[SRO_SUBJECT_ID]\n",
    "    datamodule = CogPonderDataModule(data, batch_size=CONFIG['batch_size'], num_workers=8)\n",
    "    datamodule.prepare_data()\n",
    "    print('Done!')\n",
    "\n",
    "X_train, trial_types_train, is_corrects_train, y_train, rt_train = datamodule.train_dataset[:]\n",
    "X_test, trial_types_test, is_corrects_test, y_test, rt_test = datamodule.test_dataset[:]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_ckpt.eval()\n",
    "\n",
    "    y_train_steps,p_train,rt_train_pred = model_ckpt(X_train)\n",
    "    y_test_steps,p_test,rt_test_pred = model_ckpt(X_test)\n",
    "\n",
    "    y_train_steps = torch.argmax(y_train_steps, dim=-1)\n",
    "    y_test_steps = torch.argmax(y_test_steps, dim=-1)\n",
    "\n",
    "    y_train_pred = y_train_steps.gather(dim=0, index=rt_train_pred[None, :] - 1,)[0]  # (batch_size,)\n",
    "    y_test_pred = y_test_steps.gather(dim=0, index=rt_test_pred[None, :] - 1,)[0]  # (batch_size,)\n",
    "\n",
    "    train_res = pd.DataFrame({'true_rt_train': rt_train.detach().tolist(),\n",
    "                              'pred_rt_train': rt_train_pred.tolist()})\n",
    "    test_res = pd.DataFrame({'true_rt_test': rt_test.detach().tolist(),\n",
    "                             'pred_rt_test': rt_test_pred.tolist()})\n",
    "\n",
    "    display(train_res.T, test_res.T)\n",
    "\n",
    "# DEBUG report mean-RT\n",
    "print(f'RT train mean (pred/true): '\n",
    "      f'{rt_train_pred.float().mean().item():.2f}, '\n",
    "      f'{rt_train.float().mean().item():.2f}')\n",
    "\n",
    "print(f'RT test  mean (pred/true): '\n",
    "      f'{rt_test_pred.float().mean().item():.2f}, '\n",
    "      f'{rt_test.float().mean().item():.2f}')\n",
    "\n",
    "# DEBUG - report sd-RT\n",
    "print(f'RT train std (pred/true): '\n",
    "      f'{rt_train_pred.float().std().item():.2f}, '\n",
    "      f'{rt_train.float().std().item():.2f}')\n",
    "\n",
    "print(f'RT test  std (pred/true): '\n",
    "      f'{rt_test_pred.float().std().item():.2f}, '\n",
    "      f'{rt_test.float().std().item():.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ponder')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70f45b4cee24464c60504a5fe56f777ef44c770208b66a1d7d40e1cf1ca2ecf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
